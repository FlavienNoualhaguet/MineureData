{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trees, Bagging and Boosting\n",
    "\n",
    "This lab illustrates one learning algorithm used to build decision trees and two learning meta-algorithms, the _bagging_ and the _boosting_.\n",
    "\n",
    "<font color='red'>For pedagogical reasons, we code these models _almost_ from scratch, however these models are already implemented in `sklearn`. Outside of this lab, one should use the `sklearn` implementations.</font>\n",
    "\n",
    "In this lab, we work on the Boston housing data. Using this data set we want to build a model explaining the median value of owner-occupied homes. When facing a real data set, do not hesitate to do some plots first in order to get a better insight of the data.\n",
    "\n",
    "# Decision Trees\n",
    "A decision tree is a model that splits the input space recursively into regions $R_1,\\ldots,R_M$. These regions are a partition of the input space. Each region $R_m$ is associated to a predicted value $c_k$. For all the input $x\\in R_m$, the tree model $h$ predicts $c_m$. In the regression context, we have $h(x)=\\sum_{m=1}^M c_m {\\mathbb{1}}_{R_m}(x)$.\n",
    "\n",
    "Usually, each node of the tree model is associated to one condition on one explanatory variable. Considering a new example $x$, if it satisfies the condition at the node then it goes to the left branch else it goes to the right branch. This process is repeated till a leaf is reached. The value predicted is the one associated to this leaf. The Figure 1 shows a tree model and the associated partition.\n",
    "\n",
    "<img src=\"figure.png\" width=\"700\">\n",
    "\n",
    "\n",
    "Building a tree model minimizing the error on the training set $S$ is a difficult task. Hence, a greedy recursive algorithm is used to build the tree model in a top-down fashion. First, the condition $\\mathrm{condition}$ associated to the root node is selected. Secondly, the left (resp. right) subtree is built by applying this algorithm on the examples of $S$ satisfying $\\mathrm{condition}$ (resp. $\\neg \\mathrm{condition}$). This algorithm stops when there are not enough examples to perform a split. This algorithm is described below:\n",
    "\n",
    "<img src=\"algo.png\" width=\"700\">\n",
    "\n",
    "The function ``chooseSplit`` chooses the \"best\" split $x_j\\leq t$ where $x_j$ is an explanatory variable and $t$ is the threshold of the condition. On the left leaf, we predict $c_1$ and on the right leaf we predict $c_2$. Here, the \"best\" is the one minimizing the following error on the training set:\n",
    "\\begin{equation}\n",
    "error(j,t)= \\underset{c_1}{min}~\\underset{\\substack{(x,y)\\in \\mathrm{data} \\\\ x_j\\leq t}}{\\sum} (y-c_1)^2 + \\underset{c_2}{min}~\\underset{\\substack{(x,y)\\in \\mathrm{data} \\\\ x_j > t}}{\\sum} (y-c_2)^2.\n",
    "\\end{equation}\n",
    "\n",
    "In order to control the size of the tree, ``chooseSplit`` only consider the splits that result in at least `nmin` examples on both side of the split. For this reason, sometimes, no split can be performed.\n",
    "\n",
    "\n",
    "<font color='red'>**Q1:**</font> When we select the \"best\" split, why is the number of couples $(j,t)$ to compare is finite?\n",
    "\n",
    "\n",
    "Nombre d'exemples finis et nombres de variables explicatives finis. Le range des valeurs pour la variable Xj est aussi fini car on a un nombre finis de points. On ne fera les tests que sur ces valeurs\n",
    "\n",
    "<font color='red'>**Q2:**</font> Assuming the couple $(j,t)$ is selected, what is the value of $c_1$ and $c_2$?\n",
    "La moyenne des y dans chaque classes\n",
    "\n",
    "\n",
    "<font color='red'>**Q3:**</font> The function `chooseSplit` returns the best `(j,t)` if a split is possible, `None` otherwise. Using this function, implement the function `buildTree(X, y, nmin)` described by the Algorithm above. `nmin` is used to control the growth of the tree. It is minimum number of examples in each leaf. \n",
    "\n",
    "<font color='green'>**Hints for Q3:**</font> As a reminder, considering a numpy array `a`, if `condition` is boolean numpy array with a shape similar to `a` then `a[condition]` is a numpy array containing the elements of `a` for which `condition` is true. In addition, one can use `np.logical_not`, considering a numpy boolean array `a`, `np.logical_not(a)` applies the logical operator \"not\" to each element of `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "\n",
    "def rmse(ypred, y):\n",
    "    return np.sqrt(np.mean((ypred - y) ** 2))\n",
    "\n",
    "def chooseSplit(X, y, nmin):\n",
    "    def sse(y):\n",
    "        e = y - np.mean(y)\n",
    "        return np.sum(e * e)\n",
    "    def error(j, t):\n",
    "        sel = X[:, j] <= t\n",
    "        nsel = np.logical_not(sel)\n",
    "        if np.sum(nsel) >= nmin and np.sum(sel) >= nmin:\n",
    "            s = sse(y[sel]) + sse(y[nsel])\n",
    "        else:\n",
    "            s = float('inf')\n",
    "        return (s, (j, t))\n",
    "    totest = [(j, t) for j in range(X.shape[1]) for t in X[:, j]]\n",
    "    s, (j, t) = min([error(*x) for x in totest])\n",
    "    if s == float('inf'):\n",
    "        return None\n",
    "    else:\n",
    "        return (j, t)\n",
    "    \n",
    "class Leaf:\n",
    "    '''Class storing the Leaf'''\n",
    "    def __init__(self,meany):\n",
    "        self.meany = meany\n",
    "    def __repr__(self):\n",
    "        return \"Leaf({:.2f})\".format(self.meany)\n",
    "    def predict(self, X):\n",
    "        if len(X.shape) == 1:\n",
    "            return self.meany\n",
    "        else:\n",
    "            return np.repeat(self.meany,X.shape[0])\n",
    "    def count_leaves(self):\n",
    "        return 1\n",
    "    \n",
    "class Node:\n",
    "    '''Class storing the Node'''\n",
    "    def __init__(self, split, left, right):\n",
    "        (j, t) = split\n",
    "        self.j = j\n",
    "        self.t = t\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "    def __repr__(self):\n",
    "        return \"Node(j={0.j},t={0.t:.2f},left={0.left},right={0.right})\".format(self)\n",
    "    def predict(self,X):\n",
    "        def predictone(node, Xi):\n",
    "            if isinstance(node, Leaf):\n",
    "                return node.predict(Xi)\n",
    "            elif Xi[node.j] <= node.t:\n",
    "                return predictone(node.left, Xi)\n",
    "            else:\n",
    "                return predictone(node.right, Xi)\n",
    "        return np.array([predictone(self,Xi)  for Xi in X])\n",
    "    def count_leaves(self):\n",
    "        return self.left.count_leaves()+self.right.count_leaves()\n",
    "\n",
    "def load_data():\n",
    "    df = pd.read_csv(\"BostonHousing.csv\")\n",
    "    y = df[\"medv\"].to_numpy()\n",
    "    X = df.drop(columns=[\"medv\"]).to_numpy()\n",
    "    return X,y\n",
    "    \n",
    "def main(nmin=1):\n",
    "    # returns (X, y) two numpy arrays corresponding to the Boston Housing median value prediction problem\n",
    "    X, y = load_data()#sklearn.datasets.load_boston(return_X_y=True)\n",
    "    Xts, Xvs, yts, yvs = sklearn.model_selection.train_test_split(X, y, random_state=42,train_size=350)\n",
    "    m = buildTree(Xts, yts, nmin)    \n",
    "    print(m)\n",
    "    def rmse(ypred, y):\n",
    "        return np.sqrt(np.mean((ypred - y)**2))\n",
    "    print(\"nmin:\", nmin)\n",
    "    print(\"number of leaves:\",m.count_leaves())\n",
    "    print(\"RMSE ON TRAINING SET:\", rmse(m.predict(Xts), yts))\n",
    "    print(\"RMSE ON VALIDATION SET:\", rmse(m.predict(Xvs), yvs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "prompt"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node(j=5,t=6.94,left=Node(j=12,t=14.37,left=Node(j=7,t=1.36,left=Leaf(44.48),right=Node(j=5,t=6.54,left=Node(j=5,t=6.03,left=Node(j=10,t=20.20,left=Node(j=5,t=5.76,left=Node(j=12,t=13.15,left=Leaf(17.31),right=Leaf(21.57)),right=Node(j=2,t=5.19,left=Node(j=0,t=0.06,left=Leaf(18.43),right=Leaf(20.02)),right=Node(j=6,t=30.20,left=Leaf(22.88),right=Node(j=2,t=5.96,left=Leaf(19.90),right=Node(j=8,t=4.00,left=Leaf(20.89),right=Node(j=0,t=2.24,left=Leaf(23.24),right=Leaf(20.53))))))),right=Leaf(17.52)),right=Node(j=10,t=20.20,left=Node(j=9,t=403.00,left=Node(j=11,t=387.11,left=Node(j=11,t=376.75,left=Node(j=12,t=9.81,left=Leaf(24.63),right=Leaf(22.06)),right=Leaf(27.22)),right=Node(j=5,t=6.12,left=Node(j=12,t=9.16,left=Leaf(22.63),right=Leaf(21.00)),right=Node(j=11,t=393.55,left=Leaf(22.23),right=Node(j=7,t=6.81,left=Node(j=2,t=6.96,left=Leaf(24.38),right=Node(j=5,t=6.33,left=Leaf(24.08),right=Leaf(22.74))),right=Leaf(22.52))))),right=Node(j=0,t=3.84,left=Leaf(19.58),right=Node(j=0,t=5.20,left=Leaf(23.00),right=Leaf(21.10)))),right=Node(j=0,t=0.13,left=Leaf(20.62),right=Leaf(18.74)))),right=Node(j=12,t=5.68,left=Node(j=10,t=17.80,left=Node(j=11,t=393.37,left=Leaf(30.35),right=Leaf(33.17)),right=Leaf(26.32)),right=Node(j=7,t=3.79,left=Node(j=2,t=8.56,left=Node(j=12,t=6.92,left=Leaf(30.10),right=Leaf(28.38)),right=Leaf(24.32)),right=Node(j=12,t=6.56,left=Leaf(26.22),right=Node(j=12,t=7.39,left=Leaf(24.55),right=Leaf(22.98))))))),right=Node(j=7,t=2.07,left=Node(j=0,t=6.29,left=Node(j=5,t=5.40,left=Leaf(12.57),right=Node(j=12,t=16.90,left=Leaf(17.84),right=Node(j=0,t=0.54,left=Leaf(15.96),right=Leaf(14.42)))),right=Node(j=4,t=0.67,left=Node(j=5,t=5.16,left=Leaf(13.95),right=Leaf(12.41)),right=Node(j=12,t=18.85,left=Leaf(13.90),right=Node(j=0,t=9.60,left=Node(j=4,t=0.69,left=Leaf(10.28),right=Leaf(11.98)),right=Node(j=4,t=0.69,left=Node(j=7,t=1.59,left=Leaf(6.02),right=Leaf(7.83)),right=Node(j=12,t=28.28,left=Leaf(10.30),right=Leaf(7.95))))))),right=Node(j=11,t=306.38,left=Node(j=12,t=17.31,left=Leaf(15.87),right=Node(j=5,t=6.42,left=Leaf(13.25),right=Leaf(13.75))),right=Node(j=6,t=84.40,left=Node(j=11,t=393.29,left=Node(j=9,t=391.00,left=Leaf(22.68),right=Leaf(20.45)),right=Leaf(19.43)),right=Node(j=0,t=0.17,left=Leaf(21.08),right=Node(j=6,t=91.30,left=Leaf(18.38),right=Node(j=12,t=17.60,left=Leaf(17.58),right=Leaf(15.14)))))))),right=Node(j=5,t=7.42,left=Node(j=12,t=9.59,left=Node(j=6,t=91.00,left=Node(j=6,t=76.90,left=Node(j=9,t=252.00,left=Node(j=0,t=0.06,left=Leaf(34.35),right=Leaf(36.02)),right=Node(j=9,t=358.00,left=Node(j=5,t=7.11,left=Leaf(30.48),right=Leaf(32.89)),right=Leaf(35.22))),right=Leaf(26.57)),right=Leaf(40.95)),right=Leaf(23.32)),right=Node(j=10,t=17.80,left=Node(j=0,t=0.58,left=Node(j=12,t=3.13,left=Leaf(42.32),right=Leaf(47.39)),right=Leaf(50.00)),right=Leaf(36.48))))\n",
      "nmin: 4\n",
      "number of leaves: 70\n",
      "RMSE ON TRAINING SET: 2.347589254133365\n",
      "RMSE ON VALIDATION SET: 3.667374697350373\n"
     ]
    }
   ],
   "source": [
    "def buildTree(X, y, nmin=1):\n",
    "    split = chooseSplit(X, y, nmin)\n",
    "    if split is None: return Leaf(y.mean())\n",
    "    else:\n",
    "        j, t = split\n",
    "        mask_left  = X[:, j]<=t\n",
    "        mask_right = np.logical_not(mask_left)\n",
    "        left  = buildTree(X[mask_left], y[mask_left], nmin)\n",
    "        right = buildTree(X[mask_right], y[mask_right], nmin)\n",
    "        return Node(split, left, right)\n",
    "    \n",
    "main(4) # TO UNCOMMENT WHEN buildTree HAS BEEN WRITTEN !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Q4:**</font> Using `nmin=1`, why the RMSE on the training set is 0 ? Looking at the RMSE on  the validation set, test with `nmin=4`, why the RMSE is reduced ?\n",
    "\n",
    "Les valeurs dans les feuilles sont celles du training donc RMSE=0. RMSE réduite avec nmin=4 sur le validation mais sur le training ça l'augmente. Augmentation du biais mais diminution de la variance.\n",
    "\n",
    "<font color='red'>**Q5:**</font> Rescaling the explanatory variables is an important pre-processing for some methods like neural network or penalized linear regression like Ridge for instance. For the regression tree model seen here, will it change a thing to scale the explanatory variables ? More generally, which property makes this transformation useless ?\n",
    "\n",
    "Pas de changement car les modèles d'arbres aléatoires sont invariants au scaling de transformation monotone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--bibtex \n",
    "\n",
    "@article{breiman1996bagging,\n",
    "  title={Bagging predictors},\n",
    "  author={Breiman, Leo},\n",
    "  journal={Machine learning},\n",
    "  volume={24},\n",
    "  number={2},\n",
    "  pages={123--140},\n",
    "  year={1996},\n",
    "  publisher={Springer}\n",
    "}\n",
    "@article{breiman2001random,\n",
    "  title={Random forests},\n",
    "  author={Breiman, Leo},\n",
    "  journal={Machine learning},\n",
    "  volume={45},\n",
    "  number={1},\n",
    "  pages={5--32},\n",
    "  year={2001},\n",
    "  publisher={Springer}\n",
    "}\n",
    "\n",
    "-->\n",
    "# Bagging and Random Forest\n",
    "The _bagging_ is a learning meta-algorithm proposed in [(Bagging predictors, L. Breiman, Machine Learning 1996)](https://www.stat.berkeley.edu/~breiman/bagging.pdf). Considering an unstable learning algorithm $\\mathcal{A}$ (low bias and high variance), the _bagging_ computes the mean of several models built by $\\mathcal{A}$. The new learning algorithm obtained through the bagging algorithm have a variance inferior to the variance of $\\mathcal{A}$. This variance reduction reduces the prediction error.\n",
    "\n",
    "The _random forest_ is a learning algorithm proposed in [(Random forests, L. Breiman, Machine Learning 2001)](https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf). It uses the _bagging_ with a learning algorithm that builds a tree model. This tree model is randomly distorted. With this, the estimated mean is computed over very different tree models. This reduces the variance of this estimated mean.\n",
    "## Bagging\n",
    "\n",
    "Let us consider a fixed $x_0$ and $Y_0=(Y|X=x_0)$, using a learning algorithm $\\mathcal{A}$, the _bagging_ takes advantage of the inequation below:\n",
    "$${\\mathbb{E}}_{Y_0,S}[(Y_0-\\mathcal{A}[S](x_0))^2]\\geq {\\mathbb{E}}_{Y_0}[(Y_0-{\\mathbb{E}}_{S}[\\mathcal{A}[S](x_0)])^2]$$ where $\\mathcal{A}[S]$ refers to the model obtained by calling $\\mathcal{A}$ with the training set $S$. The more the learning algorithm $\\mathcal{A}$ is unstable (high variance), the more the difference between these two quantities is large.\n",
    "\n",
    "The idea of the _bagging_ is to predict ${\\mathbb{E}}_{S}[\\mathcal{A}[S](x_0)]$ instead of predicting $\\mathcal{A}[S](x_0)$.  One issue is that we only have access to one training set $S$. To work around this problem, _bootstrap_ samples ${B_1}^{S},\\ldots,{B_b}^{S}$ of $S$ are used. Each _bootstrap_ sample ${B_i}^{S}$ can be regarded as a \"new\" training set. Then, using these ${B_i}^{S}$'s, ${\\mathbb{E}}_{S}[\\mathcal{A}[S](x_0)]$ is estimated by computing the mean of the $\\mathcal{A}[{B_i}^{S}](x_0)$.\n",
    "\n",
    "The _bootstrap_ is a resampling method. It draws a set $B$ from a set $S$ with $\\vert S\\vert=\\vert B\\vert=n$. The set $S$ is assumed to come from $n$ _i.i.d._ draws of a random variable $X$. We want to draw a new set $B$ but can not draw from the true $X$ anymore. Using the draws in $S$, the idea of the _bootstrap_ is to \"simulate\" the draw of $X$. A draw of $X$ will be \"simulated\" by drawing one element of $S$ with a uniform probability. The bootstrap sample $B$ is $n$ \"simulated\" draws.\n",
    "\n",
    "<font color='red'>**Q6:**</font> Write a function `bootstrap(X,y)` that returns a bootstrap sample of `X` and `y`.\n",
    "\n",
    "<font color='green'>**Hints for Q6:**</font> Using [`np.random.choice`](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.choice.html) (click on it to see the documentation), one can compute a variable `indexes` containing the indexes for the selected examples. Then using this `indexes` one can create new numpy arrays using the syntaxe `array[indexes]` which create a new array containing the elements of `array` at the indexes `indexes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "prompt"
    ]
   },
   "outputs": [],
   "source": [
    "def bootstrap(X, y):\n",
    "    size = X.shape[0]\n",
    "    indexes = np.random.choice(size, size=size)\n",
    "    return X[indexes], y[indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Q7:**</font> Using `bootstrap` and `sklearn.tree.DecisionTreeRegressor`, write the function `bagging(X,y,ntrees,nmin)` that return a list of trees trained using a different bootstrap sample for each tree. Note that the default behavior of `sklearn.tree.DecisionTreeRegressor()` is to grow the tree till there are not enough examples to split (just like in <font color='red'>**Q4**</font>). Here `nmin` is the minimum number of samples in each leaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "prompt"
    ]
   },
   "outputs": [],
   "source": [
    "import sklearn.tree\n",
    "def bagging(X, y, ntrees, nmin):\n",
    "    trees = []\n",
    "    for i in range(ntrees):\n",
    "        Xb, yb = bootstrap(X, y)\n",
    "        \n",
    "        t  = sklearn.tree.DecisionTreeRegressor(min_samples_leaf=nmin)\n",
    "        t.fit(X=Xb, y=yb)\n",
    "        \n",
    "        trees.append(t)\n",
    "    return trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Q8:**</font> The prediction of a bagged models is the mean of the prediction of each model (a tree here). Write `mean_predict(trees, X)` that returns the mean prediction of the trees `trees` on the input `X`.\n",
    "\n",
    "<font color='green'>**Hints for Q8:**</font> One can initialize a variable `res=0`, and then loop on `trees` to sum the prediction of the tree and then divide the prediction by the number of trees at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": [
     "prompt"
    ]
   },
   "outputs": [],
   "source": [
    "def mean_predict(trees, X): \n",
    "    y=np.mean([t.predict(X) for t in trees],axis=0)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Q9:**</font> Call the function `plotbagging`. This function trains 500 bootstrapped trees on the training set and then plots the performances on the validation sets as a function of the number of trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def predictions_from_trees(predict,trees, X):\n",
    "    return [predict(trees[:i],X) for i in range(1,len(trees)+1)]\n",
    "\n",
    "def rmses_from_predictions(predictions,y):\n",
    "    return [rmse(predi, y) for predi in predictions]\n",
    "\n",
    "def plotbagging():\n",
    "    X, y = load_data()\n",
    "    Xts, Xvs, yts, yvs = sklearn.model_selection.train_test_split(X, y, random_state=42,train_size =350)\n",
    "    ntrees = 500\n",
    "    nmin = 1\n",
    "    baggedtrees = bagging(Xts,yts,ntrees,nmin=nmin)\n",
    "    plt.plot(rmses_from_predictions(predictions_from_trees(mean_predict,baggedtrees,Xvs),yvs))\n",
    "    plt.show()\n",
    "\n",
    "plotbagging() # uncomment and call this function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "If we consider $X_1,\\ldots,X_b$ _i.i.d._ of variance $\\sigma^2$, we have ${\\mathbb{Var}}\\left[\\frac{1}{b}\\sum_{i=1}^b X_i\\right]=\\frac{\\sigma^2}{b}$. Using this fact, the bagging method averages different prediction to reduce the variance of the predicted value. This is done by predicting $\\frac{1}{b}\\sum_{i=1}^b \\mathcal{A}[{B_i}^{S}](x_0)$ instead of predicting $\\mathcal{A}[S](x_0)$. However, the variables $\\mathcal{A}[{B_i}^{S}](x_0)$ are not independent and they have a correlation coefficient $\\rho\\geq 0$. Thus, we have that ${\\mathbb{Var}}\\left[\\frac{1}{b}\\sum_{i=1}^b \\mathcal{A}[{B_i}^{S}](x_0)\\right]=\\rho \\sigma^2+\\frac{(1-\\rho)}{b}\\sigma^2$. \n",
    "\n",
    "Intuitively, the ${B_i}^{S}$ bootstrap samples are computed on the same $S$: if the drawn $S$ is different from the \"true\" distribution then all the bootstrap samples ${B_i}^{S}$ will be similar to $S$ and thus, they will be similarly different from the \"true\" distribution. \n",
    "\n",
    "The idea of the random forest is to reduce the correlation coefficient $\\rho$. To do this, the split selection is modified. If we have $p$ explanatory variables, instead of considering the $p$ variables for selecting the best split, we only consider $m$ variables. These $m$ variables are selected randomly among the $p$ variables at each split.\n",
    "\n",
    "<font color='red'>**Q10:**</font> When $m=p$, to which algorithm the random forest is equivalent ?\n",
    "\n",
    "Equivalent à CART\n",
    "\n",
    "<font color='red'>**Q11:**</font> When $m$ decreases, how the variance of the random forest algorithm vary ? Similarly, when $m$ decreases, how the bias of the random forest vary ?\n",
    "\n",
    "Quand m diminue, le biais augmente et la variance diminue (car rho diminue et simga2 constant donc rho*sigma2 diminue)\n",
    "\n",
    "<font color='red'>**Q12:**</font> Write the function `random_forest(X, y, ntrees, m, nmin)` that returns a list of tree models. To grow these trees, each split variable will be selected among a random set of $m$ variables. This set is drawn each time a split has to be selected.\n",
    "\n",
    "<font color='green'>**Hints for Q12:**</font> To enforce that each split variable will be selected among a random set of $m$ variables, you can specify the $m$ value through the parameter `max_features` of the constructor `sklearn.tree.DecisionTreeRegressor`. The code of the `random_forest` function will be very similar to the `bagging` one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "prompt"
    ]
   },
   "outputs": [],
   "source": [
    "def random_forest(X, y, ntrees, m, nmin):\n",
    "    trees = []\n",
    "    for i in range(ntrees):\n",
    "        Xb, yb = bootstrap(X, y)\n",
    "        \n",
    "        t  = sklearn.tree.DecisionTreeRegressor(min_samples_leaf=nmin, max_features=m)\n",
    "        t.fit(X=Xb, y=yb)\n",
    "        \n",
    "        trees.append(t)\n",
    "    return trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def predictions_from_trees(predict,trees, X):\n",
    "    return [predict(trees[:i],X) for i in range(1,len(trees)+1)]\n",
    "\n",
    "def rmses_from_predictions(predictions,y):\n",
    "    return [rmse(predi, y) for predi in predictions]\n",
    "\n",
    "def plotrandomforest():\n",
    "    X, y = load_data()\n",
    "    Xts, Xvs, yts, yvs = sklearn.model_selection.train_test_split(X, y, random_state=42,train_size =350)\n",
    "    ntrees = 500\n",
    "    nmin = 1\n",
    "    m = 5\n",
    "    randomForesttrees = random_forest(Xts,yts,ntrees, m=m, nmin=nmin)\n",
    "    plt.plot(rmses_from_predictions(predictions_from_trees(mean_predict,randomForesttrees,Xvs),yvs))\n",
    "    plt.show()\n",
    "\n",
    "plotrandomforest() # uncomment and call this function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "_Boosting_ is a family of meta-algorithms. Considering a high bias-low variance learning algorithm $\\mathcal{A}$, a _boosting_ meta-algorithm learns a model by combining several models obtained by using $\\mathcal{A}$. As opposed to the _bagging_, the $\\mathcal{A}$ is applied to a different learning problem at each iteration.\n",
    "\n",
    "One of the first boosting algorithm is called _AdaBoost_ ([A decision-theoretic generalization of on-line learning and an application to boosting, Y. Freund and R. Schapire, Journal of computer and system sciences, 1997](https://www.cis.upenn.edu/~mkearns/teaching/COLT/adaboost.pdf)). It modifies the weight of each examples at each iteration. Another boosting algorithm, the _gradient boosting_ ([Greedy function approximation: a gradient boosting machine, J. Friedman, Annals of statistics, 2001](https://statweb.stanford.edu/~jhf/ftp/trebst.pdf)), changes the variable to be predicted at each iteration.\n",
    "\n",
    "Considering a quadratic loss function, the _gradient boosting_ algorithm consists in fitting the residuals at each iteration. The obtained sequence of models $h_1,\\ldots,h_n$ are combined to obtain $h$: $h=\\mu+\\nu \\sum_{i=1}^n h_i$ where $\\nu \\in \\left]0;1\\right]$ is the _shrinkage_ parameter and $\\mu$ is the mean of the variable to predict.\n",
    "\n",
    "\n",
    "<img src=\"algoboost.png\" width=\"500\">\n",
    "\n",
    "<font color='red'>**Q13:**</font> The constructor `sklearn.tree.DecisionTreeRegressor(max_depth)` grows a tree with a depth inferior to `max_depth`. This parameter is usually low, leading to a high bias-low variance learning algorithm. Using this constructor, write the function `gradient_boost(X, y, ntrees, nu, max_depth)` that returns a tuple containing $\\mu$ and the list of fitted trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": [
     "prompt"
    ]
   },
   "outputs": [],
   "source": [
    "def gradient_boost(X, y, ntrees, nu, max_depth):\n",
    "    ymean = y.mean()\n",
    "    residuals = y - ymean\n",
    "    trees = []\n",
    "    \n",
    "    for i in range(ntrees):\n",
    "        h  = sklearn.tree.DecisionTreeRegressor(max_depth=max_depth)\n",
    "        h.fit(X=X, y=residuals)\n",
    "        \n",
    "        residuals = residuals - nu*h.predict(X)\n",
    "        trees.append(h)\n",
    "    return ymean, trees\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Q14:**</font> Write the function `predict_from_gb(mu, nu, trees, X)` that returns the predictions of the gradient boosted model on the input `X`. To compute this prediction you will use the model returned by`gradient_boost`. This model is a tuple containing  $\\mu$ and the list of fitted trees. In `predict_from_gb`, these two values are two parameters: `mu` and `trees`.\n",
    "\n",
    "<font color='green'>**Hints for Q14:**</font> One can start by copy-paste the code in <font color='red'>**Q8**</font> as the obtained code should be quite similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": [
     "prompt"
    ]
   },
   "outputs": [],
   "source": [
    "def predict_from_gb(mu, nu, trees, X):\n",
    "    return mu + nu*np.sum([t.predict(X) for t in trees], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**Q15:**</font> Execute the code below to plot the RMSE on the validation as a function of the number of trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DecisionTreeRegressor.fit() got an unexpected keyword argument 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m rftrees \u001b[38;5;241m=\u001b[39m random_forest(Xts,yts,ntrees,m\u001b[38;5;241m=\u001b[39mm,nmin\u001b[38;5;241m=\u001b[39mnmin)\n\u001b[1;32m     16\u001b[0m rfrmses \u001b[38;5;241m=\u001b[39m rmses_from_predictions(predictions_from_trees(mean_predict,rftrees,Xvs),yvs)\n\u001b[0;32m---> 18\u001b[0m mu, gbtrees \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_boost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntrees\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgbpredict\u001b[39m(trees,X):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predict_from_gb(mu,nu,trees,X)\n",
      "Cell \u001b[0;32mIn[43], line 8\u001b[0m, in \u001b[0;36mgradient_boost\u001b[0;34m(X, y, ntrees, nu, max_depth)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ntrees):\n\u001b[1;32m      7\u001b[0m     h  \u001b[38;5;241m=\u001b[39m sklearn\u001b[38;5;241m.\u001b[39mtree\u001b[38;5;241m.\u001b[39mDecisionTreeRegressor(max_depth\u001b[38;5;241m=\u001b[39mmax_depth)\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresiduals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     residuals \u001b[38;5;241m=\u001b[39m residuals \u001b[38;5;241m-\u001b[39m nu\u001b[38;5;241m*\u001b[39mh\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[1;32m     11\u001b[0m     trees\u001b[38;5;241m.\u001b[39mappend(h)\n",
      "\u001b[0;31mTypeError\u001b[0m: DecisionTreeRegressor.fit() got an unexpected keyword argument 'x'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "X, y = load_data()\n",
    "Xts, Xvs, yts, yvs = sklearn.model_selection.train_test_split(X, y, random_state=42,train_size =350)\n",
    "\n",
    "s=time.time()\n",
    "ntrees = 500\n",
    "nmin = 1\n",
    "nu = 0.05\n",
    "max_depth = 3\n",
    "m = 9\n",
    "\n",
    "baggedtrees = bagging(Xts,yts,ntrees,nmin=nmin)\n",
    "baggedrmses = rmses_from_predictions(predictions_from_trees(mean_predict,baggedtrees,Xvs),yvs)\n",
    "\n",
    "rftrees = random_forest(Xts,yts,ntrees,m=m,nmin=nmin)\n",
    "rfrmses = rmses_from_predictions(predictions_from_trees(mean_predict,rftrees,Xvs),yvs)\n",
    "\n",
    "mu, gbtrees = gradient_boost(Xts, yts, ntrees, nu, max_depth)\n",
    "def gbpredict(trees,X):\n",
    "    return predict_from_gb(mu,nu,trees,X)\n",
    "gbrmses = rmses_from_predictions(predictions_from_trees(gbpredict,gbtrees,Xvs),yvs)\n",
    "\n",
    "\n",
    "x = np.arange(1,ntrees+1)\n",
    "for y in [baggedrmses,rfrmses, gbrmses]:\n",
    "    plt.plot(x, y)\n",
    "plt.xlabel(\"Number of trees used\")\n",
    "plt.ylabel(\"RMSE on the validation set\")\n",
    "plt.legend(('Bagged Trees', 'Random Forest', 'Gradient Boosted Trees'), loc='upper right')\n",
    "plt.show()\n",
    "print(time.time()-s)\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
