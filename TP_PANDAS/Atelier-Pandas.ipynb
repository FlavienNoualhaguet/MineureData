{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.enac.fr/\" ><img src=\"https://www.enac.fr/themes/custom/enac/assets/images/logo_1.png\" style=\"float:left; max-width: 120px; display: inline\" alt=\"ENAC\"/></a> \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"14\">Manipulations et préparations de données avec </font>  <a href=\"https://www.python.org/\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Python_logo_and_wordmark.svg/390px-Python_logo_and_wordmark.svg.png\" style=\"max-width: 150px; display: inline\" alt=\"Python\"/></a> et <a href=\"http://pandas.pydata.org/\"><img src=\"https://pandas.pydata.org/static/img/pandas.svg\" style=\"max-width: 250px; display: inline\" alt=\"Pandas\"/></a>\n",
    "\n",
    "\n",
    "**[Science des Données](https://e-campus.enac.fr/moodle/course/view.php?id=5684), Laurent Lapasset**, *2024*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Votre notebook s'execute actuellement sur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mds6\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "print(socket.gethostname())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "**<span style=\"color:red\">Pré-requis pour utiliser ce notebook</span>** :\n",
    "\n",
    "Nous recommandons l'installation d'Ubuntu 20.04 LTS, système pour lequel tous les développements sont réalisés en premier par les GAFA, avant portage sur les autres OS.\n",
    "\n",
    "Ce notebook fonctionne avec python 3.7 sous Windows et Linux (même si ce dernier est recommandé donc).\n",
    "Il ne nécessite pas de ressources matérielles particulières.\n",
    "\n",
    "**Avant** d'installer python et les librairies, il est recommandé de travailler dans votre environnement Anaconda spécifique. Pour cela vous devez créer cet environnement avec la commande `conda create --name testenv1` où `testenv1` sera votre nouvel environnement. On peut créer autant d'environnements que l'on souhaite dans la limite de l'espace disque disponible. Ensuite pour activer cet environnement `testenv1` et \"rentrer\" dedans utiliser la commande `source activate testenv1` et installer ce que vous souhaitez, ce que nous allons voir ci-dessous. Pour avoir la liste des environnements existants utilser la comande `conda env list`. Enfin, l'ensemble des options disponibles est accessibles avec `conda --help`. \n",
    "\n",
    "On suppose maintenant que vous avez créé et activé un environnement Conda.\n",
    "\n",
    "Un certain nombre de librairies sont nécessaires pour le bon fonctionnement de ce notebook. Pour s'assurer d'une gestion cohérente et automatique des dépendances entre librairies, il est recommandé d'utiliser une des méthodes suivantes :\n",
    "\n",
    "- via l'interface graphique d'anaconda : `anaconda-navigator`\n",
    "- en ligne de commande : `conda install <librairie>`\n",
    "- en ligne de commande : `conda install -c conda-forge <librairie>`\n",
    "- en ligne de commande : `pip install <librairie>`\n",
    "\n",
    "Remarques : \n",
    "\n",
    "- en salle de TP ENAC il faut passer à travers le proxy en utilisant :\n",
    "    - l'option --proxy=http://10.222.118.213:3128 pour la commande pip.\n",
    "    - positionner les variables HTTP_PROXY et HTTPS_PROXY dans le .bashrc avec la même valeur que pour pip.\n",
    "- l'option `-c` indique le canal spécifique à partir duquel les packages peuvent être installés. `Conda` et `conda-forge` sont tous deux des gestionnaires de packages Python. `conda` est le gestionnaire de packages multiplateforme et `conda-forge` le canal de packages. Il y a quatre raisons principales d'utiliser le `conda-forge` canal au lieu du canal `defaults` maintenu par Anaconda:\n",
    "\n",
    "    - Les packages sur `conda-forge` peuvent être plus à jour que ceux sur la chaîne `defaults`<br>\n",
    "    - Certains packages sur la chaîne `conda-forge`  ne sont pas disponibles à partir de `defaults`<br>\n",
    "    - Vous préférez utiliser une dépendance telle que `openblas` (de conda-forge) au lieu de `mkl` (de defaults).<br>\n",
    "    - Si vous installez un package qui nécessite une bibliothèque compilée (par exemple, une extension C ou un wrapper autour d'une bibliothèque C), cela peut réduire le risque d'incompatibilités si vous installez tous les packages dans un environnement à partir d'un seul canal en raison de la compatibilité binaire de la bibliothèque C (mais cet avis peut être obsolète / changer dans le futur).<br>\n",
    "\n",
    "- sur la dernière version d'Ubuntu 20.04 LTS c'est python 3 qui est installé par défaut. A partir de cette release il n'ai plus nécessaire d'utiliser pip3 à la place de pip.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Résumé**:  \n",
    "\n",
    "Nous allons utiliser Python pour la préparation (*data munging* ou *wrangling*) de données qui tiennent en mémoire une fois réorganisées. Nous allons aborder les fonctionnalités de la librairie `pandas` et à la classe `DataFrame` : lire et écrire des fichiers ; apprendre à gérer une table de données et les types des variables ; échantillonner ; discrétiser ; regrouper des modalités ; faire des descriptions élémentaires uni et bi-variées ; réaliser une concaténation et jointure de tables.\n",
    "\n",
    "La dernière partie optionnelle, illustre la mise en oeuvre de `Pandas` sur le problème du Titanic et c'est l'occasion d'appliquer et de compléter la visualisation de données exposée dans l'atelier dédié `Atelier-DataViz-Graph.ipyn`, en utilisant une nouvelle librairie [`Graphviz`](https://graphviz.org/), en calculant les courbes ROC et AUC, et la matrice de confusion. Cette dernière partie fait appel à des méthodes qui sont enseignées tout au long de la formation, aussi elle ne peut être correctement réalisée qu'en fin de cursus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Objectifs\n",
    "\n",
    "Le *data munging* ou *wrangling* de données est l'ensemble des opérations permettant de passer de données brutes à une table (*data frame*) correcte et adaptée aux objectifs à atteindre par des méthodes statistiques d'analyse, d'exploration, de modélisation ou d'apprentissage. Nous utiliserons souvent les termes *manipulations* et *transformations* dans le cadre de ce notebook.\n",
    "\n",
    "En présence de données complexes, peu ou mal organisées, présentant des trous, trop massives pour tenir en mémoire...  la qualité de cette étape est fondamentale (*garbage in garbage out*) pour la bonne réalisation d'une étude. Compte tenu de la diversité des situations envisageables, il serait vain de vouloir exposer tous les outils et techniques qui peuvent s'avérer nécessaires. Tâchons néanmoins de résumer les problèmes qui peuvent être rencontrés.\n",
    "\n",
    "## Croissance du volume des données\n",
    "\n",
    "Le volume des données et sa croissance occasionnent schématiquement trois situations :\n",
    "\n",
    "1. Le fichier initial des données brutes peut être chargé *intégralement* en mémoire moyennant éventuellement de sauter quelques colonnes ou lignes du fichier (cf. section  3.1). C'est la situation la plus courante, tout logiciel statistique comme R peut réaliser les traitements. *C'est l'objet des prochaines sections de ce notebooks.\n",
    "2. Le fichier initial est très volumineux mais la table (*DataFrame*), qui résulte de quelques manipulations (*munging*) appropriés, tient en mémoire. Cette situation nécessite : lecture, analyse, transformation, ré-écritures séquentielles du fichier ligne à ligne ou par bloc. Il existe des astuces avec R mais il est préférable d'utiliser des outils plus adaptés. Tout langage de programmation (java, c, perl, ruby...) peut être utilisé pour écrire le ou les programmes réalisant ce travail. Néanmoins Python, et plus précisément la librairie [`pandas`](http://pandas.pydata.org/), offre un ensemble d'outils efficaces pour accomplir ces tâches sans avoir à ré-inventer la roue et ré-écrire tout un ensemble de fonctionnalités relativement basiques. Remarque : les procédures `univariate` et `freq` et l'étape `data` de Statistical Analysis System (SAS) sont adaptées car elles ne chargent pas les données en mémoire pour réaliser des traitements simples. Néanmoins pour tout un tas de raisons trop longues à exposer, notamment de coût annuel de location, SAS perd régulièrement des parts de marché sur ce créneau. *Cette approche est introduite ci-dessous et consiste à enchâsser dans une même structure itérative et séquentielle les étapes précédentes.\n",
    "3. Lorsque les données, très massives trop pour être entièrement chargées en mémoire, sont donc archivées sur un système de données distribuées (*Hadoop Distributed File System* ou HDFS par exmple que nous verrons en cours), ces manipulations et prétraitements doivent tenir compte alors de cet environnement : *Spark* et l'API `PySpark` permettant de gérer en python des données distribuées est à favoriser. *Cf. les [cours Hadoop et Spark](https://e-campus.enac.fr/moodle/course/view.php?id=15036#section-11)* concernés. \n",
    "\n",
    "### Quelques problèmes\n",
    "\n",
    "Liste non exhaustive des problèmes pouvant être rencontrés et dont la résolution nécessite simultanément des compétences en Informatique, Statistique, Mathématiques et aussi \"métier\" du domaine de l'étude : \n",
    "\n",
    "-  Identifier les \"individus\" $\\times$ \"variables\" (*instances*$\\times$*features* en langue informatique) de la table à mettre en forme à partir de bases de données variées; *i.e.* logs d'un site web, listes d'incidents, localisations...\n",
    "- Données atypiques (*outliers*): correction, suppression, transformation des variables ou méthode statistique robuste\n",
    "- Variable qualitative avec beaucoup de modalités dont certaines très peu fréquentes : suppression, modalité `autres`, recodage aléatoire, regroupement \"métier\" ou méthode tolérante\n",
    "- Distributions anormales (log-normale, Poisson, multimodales...) et problèmes d'hétéroscédasticité : transformation, discrétisation ou méthodes tolérantes\n",
    "- Données manquantes: suppressions (ligne ou colonne), imputation ou méthodes tolérantes\n",
    "- Représentations (splines, Fourier, ondelettes) et recalage (*time warping*) de données fonctionnelles.\n",
    "- Représentation de trajectoires, de chemins sur un graphe\n",
    "- Choix d'une distance (quadratique, absolue, géodésique...) entre les objets étudiés.\n",
    "- ...\n",
    "\n",
    "Bien entendu les \"bons\" choix dépendent directement de l'objectif poursuivi et des méthodes mises en oeuvre par la suite. D'où l'importance d'intégrer de façon précoce, dès la planification du recueil des données, les compétences statistiques nécessaires au sein d'une équipe.\n",
    "\n",
    "### Fonctionnalités de `pandas`\n",
    "\n",
    "La richesse des fonctionnalités de la librairie `pandas` est une des raisons, si ce n'est la principale,  d'utiliser Python pour extraire, préparer, éventuellement analyser, des données. En voici un bref aperçu. \n",
    "- *Objets* : les classes `Series` et `DataFrame` ou *table de données*.\n",
    "- *Lire, écrire* création et exportation de tables de données à partir de fichiers textes (séparateurs, `.csv`, format fixe, compressés), binaires (HDF5 avec `Pytable`), HTML, XML, JSON, MongoDB, SQL... \n",
    "- *Gestion* d'une table : sélection des lignes, colonnes, transformations, réorganisation par niveau d'un facteur, discrétisation de variables quantitatives, exclusion ou imputation élémentaire de données manquantes, permutation et échantillonnage aléatoire, variables indicatrices, chaînes de caractères...\n",
    "- *Statistiques* élémentaires uni et bivariées, tri à plat (nombre de modalités, de valeurs nulles, de valeurs manquantes...), graphiques associés, statistiques par groupe, détection élémentaire de valeurs atypiques...\n",
    "- *Manipulation* de tables : concaténations, fusions, jointures, tri, gestion des types et formats...\n",
    "\n",
    "### Références\n",
    "\n",
    "Je remercie Brendan Guillouet et Philippe Besse de l'INSA Toulouse pour leur [notebook](https://github.com/wikistat) dont cet atelier s'inspire, qui lui-même s'inpire fortement du livre de référence (Mc Kinney, 2013) et de la [documentation en ligne](http://pandas.pydata.org/pandas-docs/stable/) à consulter sans modération. Cette documentation inclut également des [tutoriels](http://pandas.pydata.org/pandas-docs/stable/tutorials.html) à exécuter pour compléter et approfondir cette première initiation, sur un sujet relativement technique, et qui peut prendre des tournures très diverses en fonction de la qualité et des types de données traitées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les classes `Series` et `DataFrame`\n",
    "De même que la librairie `Numpy` introduit le type `array` indispensable à la manipulation de matrices en calcul scientifique, celle `pandas` introduit les classes `Series` (séries chronologiques) et  `DataFrame` ou table de données indispensables en statistique. \n",
    "\n",
    "## *Series*\n",
    "La classe `Series` est l'association de deux `arrays` unidimensionnels. Le premier est un ensemble de valeurs indexées par le 2ème qui est souvent une série temporelle.  Ce type est introduit principalement pour des applications en Econométrie et Finance où Python est largement utilisé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *DataFrame*\n",
    "Cette classe est proche de celle du même nom dans le langage R, il s'agit d'associer avec le même index de lignes des colonnes ou variables de types différents (entier, réel, booléen, caractère). C'est un tableau bi-dimensionnel avec des index de lignes et de colonnes mais il peut également être vu comme une liste de `Series` partageant le même index. L'index de colonne (noms des variables) est un objet de type `dict` (dictionnaire). C'est la classe qui sera principalement utilisée dans ce tutoriel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year   state  pop\n",
       "0  2000    Ohio  1.5\n",
       "1  2001    Ohio  1.7\n",
       "2  2002    Ohio  3.6\n",
       "3  2001  Nevada  2.4\n",
       "4  2002  Nevada  2.9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemple de data frame\n",
    "import pandas as pd\n",
    "data = {\"state\": [\"Ohio\", \"Ohio\", \"Ohio\", \n",
    "       \"Nevada\", \"Nevada\"],\n",
    "     \"year\": [2000, 2001, 2002, 2001, 2002],\n",
    "     \"pop\": [1.5, 1.7, 3.6, 2.4, 2.9]}\n",
    "frame = pd.DataFrame(data)\n",
    "# ordre des colonnes\n",
    "pd.DataFrame(data, columns=[\"year\", \"state\", \"pop\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>pop</th>\n",
       "      <th>debt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>2000</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>2001</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>2002</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>3.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four</th>\n",
       "      <td>2001</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>five</th>\n",
       "      <td>2002</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year   state  pop debt\n",
       "one    2000    Ohio  1.5  NaN\n",
       "two    2001    Ohio  1.7  NaN\n",
       "three  2002    Ohio  3.6  NaN\n",
       "four   2001  Nevada  2.4  NaN\n",
       "five   2002  Nevada  2.9  NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index des lignes et valeurs manquantes (NaN)\n",
    "frame2=pd.DataFrame(data, columns=[\"year\", \"state\", \"pop\", \"debt\"],\n",
    "     index=[\"one\", \"two\", \"three\", \"four\", \"five\"])\n",
    "# liste des colonnes\n",
    "frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coucou\n"
     ]
    }
   ],
   "source": [
    "print(\"coucou\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ceci est du test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "c=a+b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Ohio\n",
       "1    Ohio\n",
       "Name: state, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Les deux première valeurs d'une colonne\n",
    "frame[\"state\"][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toutes les valeurs d'une colonne\n",
    "frame[\"state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2000\n",
       "1    2001\n",
       "2    2002\n",
       "3    2001\n",
       "4    2002\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"imputation\"\n",
    "frame2[\"debt\"] = 16.5\n",
    "frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state</th>\n",
       "      <th>pop</th>\n",
       "      <th>debt</th>\n",
       "      <th>eastern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>2000</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>2001</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>2002</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>3.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four</th>\n",
       "      <td>2001</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>five</th>\n",
       "      <td>2002</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>2.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year   state  pop debt  eastern\n",
       "one    2000    Ohio  1.5  NaN     True\n",
       "two    2001    Ohio  1.7  NaN     True\n",
       "three  2002    Ohio  3.6  NaN     True\n",
       "four   2001  Nevada  2.4  NaN    False\n",
       "five   2002  Nevada  2.9  NaN    False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# créer une  variable\n",
    "frame2[\"eastern\"] = frame2.state == \"Ohio\"\n",
    "frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'state', 'pop', 'debt', 'eastern'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'state', 'pop', 'debt'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# supprimer une  variable\n",
    "del frame2[u\"eastern\"]\n",
    "frame2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index\n",
    "Les index peuvent être définis par emboîtement et beaucoup d'autres fonctionnalités sur la gestion des index sont décrites par Mac Kinney (2013) (chapitre 5) : \n",
    "- `append` nouvel index par concaténation,\n",
    "- `diff` différence ensembliste,\n",
    "- `intersection` intersection ensembliste,\n",
    "- `union` union ensembliste\n",
    "- `isin` vrai si la valeur est dans la liste,\n",
    "- `delete` suppression de l'index $i$,\n",
    "- `drop` suppression d'une valeur d'index, \n",
    "- `is_monotonic` vrai si les valeurs sont croissantes, \n",
    "- `is_unique` vrai si toutes les valeurs sont différentes, \n",
    "- `nique` tableau des valeurs uniques de l'index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lire écrire des tables de données\n",
    "`Pandas` offre des outils efficaces pour lire écrire des fichiers selon différents formats (csv, texte, fixe, compressé, xml, html, hdf5) ou interagir avec des bases de données SQL, MongoDB, des APIs web. Ce document se contente de décrire les fonctions les plus utiles `read_csv` et `read_table` pour lire des fichiers textes et générer un objet de classe ` DataFrame`. \n",
    "\n",
    "En principe ces fonctions font appel à un code écrit en C dont très rapide à l'exécution sauf pour l'emploi de certaines options (`skip\\_footer, sep`} autre qu'un seul caractère), à éviter, qui provoquent une exécution en Python (`engine=Python`). \n",
    "\n",
    "La réciproque pour l'écriture est obtenue par les commandes `data.to_csv` ou `_table` avec des options similaires. \n",
    "\n",
    "## Syntaxe\n",
    "L'exemple de base est donné pour lire un fichier au format `.csv` dont les valeurs sont séparées par des \",\" et dont la première ligne contient le nom des variables.\n",
    "``\n",
    "import pandas as pd\n",
    "data=pd.read_csv(\"fichier.csv\")\n",
    "data=pd.read_table(\"fichier.csv\", sep=\",\")\n",
    "``\n",
    "\n",
    "Il est important de connaître la liste des possibilités et options offertes par cette simple commande. Voici les principales ci-dessous et un lien à la [liste complète](http://pandas.pydata.org/pandas-docs/stable/io.html#io-read-csv-table).\n",
    "- `path` chemin ou non du fichier ou URL.\n",
    "- `sep` délimiteur comme \\verb+ , ; | \\t + ou \\verb# \\s+ #  pour un nombre variable d'espaces. \n",
    "- `header` défaut 0, la première ligne contient le nom des variables; si `None` les noms sont générés ou définis par ailleurs.\n",
    "- `index_col` noms ou numéros de colonnes définissant les index de lignes, index pouvant être hiérarchisés comme les facteurs d'un plan d'expérience.\n",
    "- `names` si {\\\\t header=None}, liste des noms des variables. \n",
    "- `nrows` utile pour tester et limiter le nombre de ligne à lire.\n",
    "- `skiprow` liste de lignes à sauter en lecture.\n",
    "- `skip_footer` nombre de lignes à sauter en fin de fichier.\n",
    "- `na_values` définition du ou des codes signalant des valeurs manquantes. Ils peuvent être définis dans un dictionnaire pour associer variables et codes de valeurs manquantes spécifiques.\n",
    "- `usecols` sélectionne une liste des variable à lire pour éviter de lire des champs ou variables volumineuses et inutiles.\n",
    "- `skip_blan_lines` à `True` pour sauter les lignes blanches.\n",
    "- `converters` appliquer une fonction à une colonne ou variable.\n",
    "- `day_first` par défaut `False`, pour des dates françaises au format `7/06/2013`.\n",
    "- `chunksize` taille des morceaux à lire itérativement.\n",
    "- `verbose` imprime des informations comme le nombre de valeurs manquantes des variables non numériques.\n",
    "- `encoding` type d'encodage comme \"utf-8\" ou \"latin-1\"\n",
    "- `thousand` séparateur des miliers: \".\" ou \",\".\n",
    "\n",
    "Remarques:\n",
    "- De nombreuses options de gestion des dates et séries ne sont pas citées.\n",
    "- `chunksize` provoque la lecture d'un gros fichiers par morceaux de même taille (nombre de lignes). Des fonctions (comptage, dénombrement...) peuvent ensuite s'appliquer itérativement sur les morceaux.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple\n",
    "Les données du naufrage du Titanic  illustrent l'utilisation de `pandas`. Elles sont lues directement à partir de leur URL ou sinon les charger [ici](https://e-campus.enac.fr/moodle/course/view.php?id=15036#section-11) vers le répertoire de travail de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex  Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male   22      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
       "2                             Heikkinen, Miss. Laina  female   26      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
       "4                           Allen, Mr. William Henry    male   35      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# tester la lecture\n",
    "# path=\"\"\n",
    "path='./'\n",
    "df = pd.read_csv(path+'titanic-train.csv',nrows=5)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex  Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male   22      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
       "2                             Heikkinen, Miss. Laina  female   26      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
       "4                           Allen, Mr. William Henry    male   35      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tout lire\n",
    "df = pd.read_csv(path+\"titanic-train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    891\n",
       "Survived       891\n",
       "Pclass         891\n",
       "Name           891\n",
       "Sex            891\n",
       "Age            714\n",
       "SibSp          891\n",
       "Parch          891\n",
       "Ticket         891\n",
       "Fare           891\n",
       "Cabin          204\n",
       "Embarked       889\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifions également les valeurs manquantes dans les colonnes qui nous intéressent, et décidons ensuite de ce qu'il faut en faire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nan_count(column):\n",
    "    '''\n",
    "    column - the column for which we want the NaN value count.\n",
    "    This function returns the number of NaN values in a specific column.\n",
    "    '''\n",
    "    nan_count = column.isnull().sum()\n",
    "    return nan_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nan_count(df['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nan_count(df['Pclass'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nan_count(df['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nan_count(df['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nan_count(df['Embarked'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans l'ensemble, notre analyse ne devra pas prendre les valeurs manquantes pour **la classe de billet** et le **sexe**. Nous ne tiendrons pas compte des valeurs manquantes pour les colonnes **Âge** et **Embarked**.\n",
    "La colonne **Âge** ayant 177 valeurs nulles pour 891 passagers, les résultats pourraient être moins fiables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex  Age  SibSp  Parch     Fare Embarked\n",
       "0         0       3    male   22      1      0   7.2500        S\n",
       "1         1       1  female   38      1      0  71.2833        C\n",
       "2         1       3  female   26      0      0   7.9250        S\n",
       "3         1       1  female   35      1      0  53.1000        S\n",
       "4         0       3    male   35      0      0   8.0500        S"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Des variables sont inexploitables\n",
    "# Choisir les colonnes utiles\n",
    "df=pd.read_csv(path+\"titanic-train.csv\",\n",
    "    usecols=[1,2,4,5,6,7,9,11],nrows=5)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À partir de la version 0.15, `pandas`, inclut un type `category` (assez proche de celui ` factor` de R). Il devrait normalement être déclaré dans un dictionnaire au moment par exemple de la lecture (`dtype={\"Surv\":pd.Categorical...}`) mais ce n'est pas le cas, c'est donc le type objet qui est déclaré puis modifié. Il est vivement recommandé de bien affecter les bons types à chaque variable ne serait-ce que pour éviter de faire des opérations douteuses, par exemple arithmétiques sur des codes de modalités."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Surv</th>\n",
       "      <th>Classe</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Age</th>\n",
       "      <th>Prix</th>\n",
       "      <th>Port</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Surv Classe   Genre   Age     Prix Port\n",
       "0    0      3    male  22.0   7.2500    S\n",
       "1    1      1  female  38.0  71.2833    C\n",
       "2    1      3  female  26.0   7.9250    S\n",
       "3    1      1  female  35.0  53.1000    S\n",
       "4    0      3    male  35.0   8.0500    S"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(path+\"titanic-train.csv\",skiprows=1,header=None,usecols=[1,2,4,5,9,11],\n",
    "  names=[\"Surv\",\"Classe\",\"Genre\",\"Age\",\"Prix\",\"Port\"],dtype={\"Surv\":object,\n",
    "    \"Classe\":object,\"Genre\":object,\"Port\":object})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Surv       object\n",
       "Classe     object\n",
       "Genre      object\n",
       "Age       float64\n",
       "Prix      float64\n",
       "Port       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redéfinition des bons types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Surv      category\n",
       "Classe    category\n",
       "Genre     category\n",
       "Age        float64\n",
       "Prix       float64\n",
       "Port      category\n",
       "dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Surv\"]=pd.Categorical(df[\"Surv\"],ordered=False)\n",
    "df[\"Classe\"]=pd.Categorical(df[\"Classe\"],ordered=False)\n",
    "df[\"Genre\"]=pd.Categorical(df[\"Genre\"],ordered=False)\n",
    "df[\"Port\"]=pd.Categorical(df[\"Port\"],ordered=False)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarque : il est également possible de tout lire avant de laisser \"tomber\" les variable inexploitables. C'est le rôle de la commande: \n",
    "\n",
    "`df = df.drop([\"Name\", \"Ticket\", \"Cabin\"], axis=1)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Echantillonnage simple\n",
    "Le type `DataFrame` de Python est chargé en mémoire. Si, malgré les options précédentes permettant de sélectionner, les colonnes, les types des variables... le fichier est encore trop gros, il reste possible, avant de chercher une configuration matérielle lourde et en première approximation, de tirer un échantillon aléatoire simple selon une distribution uniforme. Un tirage stratifié demanderait plus de travail. Cela suppose de connaître le nombre de ligne du fichier ou une valeur inférieure proche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Surv</th>\n",
       "      <th>Classe</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Age</th>\n",
       "      <th>Prix</th>\n",
       "      <th>Port</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>56.0</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Surv  Classe   Genre   Age     Prix Port\n",
       "0       1       3  female  26.0   7.9250    S\n",
       "1       0       1    male  54.0  51.8625    S\n",
       "2       1       1  female  58.0  26.5500    S\n",
       "3       0       3    male  39.0  31.2750    S\n",
       "4       1       2    male   NaN  13.0000    S\n",
       "..    ...     ...     ...   ...      ...  ...\n",
       "195     1       2  female  28.0  24.0000    C\n",
       "196     0       3    male   NaN   7.8958    S\n",
       "197     1       1  female  56.0  83.1583    C\n",
       "198     1       2  female  25.0  26.0000    S\n",
       "199     0       3    male  33.0   7.8958    S\n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pour les données titanic:\n",
    "N=891  # taille du fichier\n",
    "n=200  # taille de l'échantillon\n",
    "lin2skipe=[0] # ne pas lire la première ligne\n",
    "# ne pas lire N-n lignes tirées aléatoirement\n",
    "lin2skipe.extend(np.random.choice(np.arange(1,N+1),\n",
    "    (N-n),replace=False))\n",
    "df_small=pd.read_csv(path+\"titanic-train.csv\",\n",
    "    skiprows=lin2skipe,header=None, \n",
    "    usecols=[1,2,4,5,9,11],\n",
    "    names=[\"Surv\",\"Classe\",\"Genre\",\"Age\",\n",
    "         \"Prix\",\"Port\"])\n",
    "df_small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gérer une table de données\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrétisation d'une variable quantitative\n",
    "\n",
    "Pour la discrétisation d'une variable quantitative. Il est d'un bon usage de définir les bornes des classes à des quantiles, plutôt qu'également espacées, afin de construire des classes d'effectifs sensiblement égales.  Ceci est obtenu par la fonction `qcut`. La fonction `cut` propose par défaut des bornes équi-réparties à moins de fournir une liste de ces bornes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     891\n",
       "unique      3\n",
       "top       Pr1\n",
       "freq      308\n",
       "Name: PrixQ, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"AgeQ\"]=pd.qcut(df.Age,3,labels=[\"Ag1\",\"Ag2\",\n",
    "   \"Ag3\"])\n",
    "df[\"PrixQ\"]=pd.qcut(df.Prix,3,labels=[\"Pr1\",\"Pr2\",\n",
    "   \"Pr3\"])\n",
    "df[\"PrixQ\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifier / regrouper des modalités\n",
    "Le recodage des variables qualitatives ou renommage en clair des modalités est obtenu simplement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Surv\"]=df[\"Surv\"].cat.rename_categories(\n",
    "    [\"Vnon\",\"Voui\"])\n",
    "df[\"Classe\"]=df[\"Classe\"].cat.rename_categories(\n",
    "    [\"Cl1\",\"Cl2\",\"Cl3\"])\n",
    "df[\"Genre\"]=df[\"Genre\"].cat.rename_categories(\n",
    "    [\"Gfem\",\"Gmas\"])\n",
    "df[\"Port\"]=df[\"Port\"].cat.rename_categories(\n",
    "    [\"Pc\",\"Pq\",\"Ps\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est possible d'associer recodage et regroupement des modalités en définissant un dictionnaire de transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"food\":[\"bacon\",\"pulled pork\", \n",
    "   \"bacon\", \"Pastrami\",\n",
    "   \"corned beef\", \"Bacon\", \"pastrami\", \"honey ham\",\n",
    "   \"nova lox\"],\n",
    "   \"ounces\": [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meat_to_animal = {\n",
    "    \"bacon\": \"pig\",\n",
    "    \"pulled pork\": \"pig\",\n",
    "    \"pastrami\": \"cow\",\n",
    "    \"corned beef\": \"cow\",\n",
    "    \"honey ham\": \"pig\",\n",
    "    \"nova lox\": \"salmon\"\n",
    "}\n",
    "# Eviter les mélanges de majuscules minuscules \n",
    "# en mettant tout en minuscule\n",
    "data[\"animal\"] = data[\"food\"].map(\n",
    "    str.lower).map(meat_to_animal)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"food\"].map(lambda x: meat_to_animal[x.lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.DataFrame({\"key\": [\"b\", \"b\", \"a\", \"c\",\n",
    "    \"a\", \"b\"],\"data1\": range(6)})\n",
    "pd.get_dummies(dfs[\"key\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables indicatrices\n",
    "Générer des indicatrices des modalités ou *dummy variables*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(dfs['key'], prefix='key')\n",
    "df_with_dummy = dfs[['data1']].join(dummies)\n",
    "df_with_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation et tirage aléatoires\n",
    "\n",
    "Permutation aléatoire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.DataFrame(np.arange(5 * 4).reshape(5, 4))\n",
    "sampler = np.random.permutation(5)\n",
    "sampler\n",
    "dfs\n",
    "dfs.take(sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tirage aléatoire avec remplacement ou *bootstrap* ; celui sans remplacement est traité dans la section dédiée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = np.array([5, 7, -1, 6, 4])\n",
    "sampler = np.random.randint(0, len(bag), size=10)\n",
    "draws = bag.take(sampler)\n",
    "draws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations, opérations\n",
    "Les opérations arithmétiques entre `Series` et `DataFrame` sont possibles au même titre qu'entre `array`. Si les index ne correspondent pas, des valeurs manquantes (NAN) sont créées à moins d'utiliser des méthodes d'arithmétique `flexible` (`add, sub, div, mul`) autorisant la complétion par une valeur par défaut, généralement 0.\n",
    "\n",
    "Une fonction quelconque (`lambda`) peut être appliquée avec une même commande qu'`apply` de R. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la table de données\n",
    "frame = pd.DataFrame(np.random.randn(4,3), \n",
    "    columns=list(\"bde\"),\n",
    "    index=[\"Utah\", \"Ohio\", \"Texas\", \"Oregon\"])\n",
    "# une fonction\n",
    "f = lambda x: x.max() - x.min()\n",
    "frame.apply(f, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tri et rangs\n",
    "Trier une table selon les valeurs d'une variable ou d'un index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(np.arange(8).reshape((2,4)), \n",
    "        index=[\"three\", \"one\"],\n",
    "        columns=[\"d\", \"a\", \"b\", \"c\"])\n",
    "frame.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.sort_index(axis=1, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.sort_values(by=\"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La commande `rank` remplace les valeurs par leur rang dans l'ordre des lignes ou des colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame({\"b\": [4.3, 7, -3, 2], \n",
    "    \"a\": [0, 1, 0, 1],\"c\": [-2, 5, 8, -2.5]})\n",
    "frame.rank(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.rank(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistiques descriptives élémentaires\n",
    "Continuons l'étude des données sur le naufrage du Titanic. Les commandes ci-dessous permettent des premiers diagnostics sur la qualité des données.\n",
    "## Description univariée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age\"].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age\"].plot(kind=\"box\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Prix\"].plot(kind=\"hist\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qualitatif\n",
    "df[\"Surv\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Classe\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Genre\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Port\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description bivariée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind=\"scatter\",x=\"Age\",y=\"Prix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# afficher une sélection\n",
    "df[df[\"Age\"]>60][[\"Genre\",\"Classe\",\"Age\",\"Surv\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column=\"Age\",by=\"Classe\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column=\"Prix\",by=\"Surv\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table de contingence\n",
    "table=pd.crosstab(df[\"Surv\"],df[\"Classe\"])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mosaic plot\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "mosaic(df,[\"Classe\",\"Genre\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic(df,[\"Surv\",\"Classe\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation de données manquantes\n",
    "La gestion des données manquantes est souvent un point délicat. De nombreuses stratégies ont été élaborées. Nous ne décrivons ici que les plus élémentaires à [mettre en oeuvre](http://pandas.pydata.org/pandas-docs/version/0.15.2/missing_data.html) avec `pandas`.\n",
    "\n",
    "Il est ainsi facile de supprimer toutes les observations présentant des données manquantes lorsque celles-ci sont peu nombreuses et majoritairement regroupées sur certaines lignes ou colonnes.\n",
    "\n",
    "``\n",
    "df = df.dropna(axis=0)\n",
    "df = df.dropna(axis=1)\n",
    "``\n",
    "\n",
    "`Pandas` permet également de faire le choix pour une variable qualitative de considérer `np.nan` comme une modalité spécifique ou d'ignorer l'observation correspondante.\n",
    "\n",
    "Autres stratégies :\n",
    "* Cas quantitatif : une valeur manquante est imputée par la moyenne ou la médiane.\n",
    "* Cas d'une série chronologique : imputation par la valeur précédente ou suivante ou par interpolation linéaire, polynomiale ou encore lissage spline.\n",
    "* Cas qualitatif : modalité la plus fréquente ou répartition aléatoire selon les fréquences observées des modalités.\n",
    "\n",
    "La variable âge contient de nombreuses données manquantes. La fonction `fillna` présente plusieurs options d'imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplacement par la médiane d'une variable quantitative\n",
    "#df=df.fillna(df.median())\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# par la modalité \"médiane\" de AgeQ\n",
    "df.info()\n",
    "df.AgeQ=df[\"AgeQ\"].fillna(\"Ag2\")\n",
    "# par le port le plus fréquent\n",
    "df[\"Port\"].value_counts()\n",
    "df.Port=df[\"Port\"].fillna(\"Ps\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces imputations sont assez rudimentaires et d'autres sont à privilégier pour des modélisations plus soignées mais ces méthodes font appel généralement à d'autres outils.\n",
    "\n",
    "D'autres fonctions (Mac Kinney, 2013) sont proposées pour supprimer les duplicatas (` drop\\_duplicates`), modifier les dimensions, traquer des anomalies unidimensionnelles, selon un modèle gaussien ou par rapport à des quantiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipuler des tables de données\n",
    "\n",
    "## Jointure\n",
    "Il s'agit de \"jointer\" deux tables partageant la même clef ou encore de concaténer horizontalement les lignes en faisant correspondre les valeurs d'une variable clef qui peuvent ne pas être uniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tables\n",
    "df1 = pd.DataFrame({\"key\": [\"b\", \"b\", \"a\", \"c\", \n",
    "     \"a\",\"a\", \"b\"],\"data1\": range(7)})\n",
    "df2 = pd.DataFrame({\"key\": [\"a\", \"b\", \"d\"],\n",
    "    \"data2\": range(3)})\n",
    "pd.merge(df1,df2,on=\"key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La gestion des clefs manquantes est en option : entre autres, ne pas introduire de ligne (ci-dessus), insérer des valeurs manquantes ci-dessous. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valeurs manquantes\n",
    "pd.merge(df1,df2,on=\"key\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concaténation selon un axe\n",
    "Concaténation verticale (axis=0) ou horizontales (axis=1) de tables. La concaténation horizontale est similaire à la jointure (option `outer`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tables\n",
    "df1 = pd.DataFrame({\"key\": [\"b\", \"b\", \"a\", \"c\", \n",
    "    \"a\", \"a\", \"b\"],\"var\": range(7)})\n",
    "df2 = pd.DataFrame({\"key\": [\"a\", \"b\", \"d\"],\n",
    "    \"var\": range(3)})\n",
    "# concaténation verticales\n",
    "pd.concat([df1,df2],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concaténation horizontale\n",
    "pd.concat([df1,df2],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulations séquentielles de gros fichiers\n",
    "\n",
    "Étape suivante associée à la croissance du volume : les fichiers des données brutes ne tiennent pas en mémoire.  Il \"suffit\" d'intégrer ou enchâsser les étapes des sections précédentes dans la lecture séquentielle d'un gros fichier. En apparence simple d'un point de vue méthodologique, cette étape peut consommer beaucoup de temps par tests et remises en causes incessantes des choix de sélection, transformation, recodage... des variables. Il est crucial de se doter d'outils efficaces. \n",
    "\n",
    "Il s'agit donc de lire les données par morceau (nombre fixé de lignes) ou ligne à ligne, traiter chaque morceau, le ré-écrire dans un fichier de format binaire plutôt que texte ; le choix du format HDF5 semble le plus efficace du point de vue technique et pour servir d'interface à d'autres environnements : C, java, Matlab... et R car une librairie (rhdf5 de Bioconductor) gère ce format.\n",
    "\n",
    "La procédure est comparable à une étape `Data` de SAS, qui lit/écrit les tables ligne à ligne.\n",
    "\n",
    "Deux librairies: `h5py` et `PyTables` gèrent le format HDF5 en Python. Pour simplifier la tâche, `pandas` intègre une classe `HDFStore` utilisant `PyTables` qui doit donc être installée. \n",
    "\n",
    "**Attention**: ce format n'est pas adapté à une gestion *parallélisée*, notamment en écriture. \n",
    "\n",
    "\n",
    "## Lecture séquentielle\n",
    "\n",
    "L'exemple est ici donné pour lire un fichier texte mais beaucoup d'autres formats (excel, hdf, sql, json, msgpack, html, gbq, stata, clipboard, pickle) sont connus de `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# lire tout le fichier par morceaux\n",
    "# avec l'option chunksize\n",
    "Partition=pd.read_csv(path+\"titanic-train.csv\",skiprows=1,\n",
    "  header=None,usecols=[1,2,4,5,9,11],\n",
    "  names=[\"Surv\",\"Classe\",\"Genre\",\"Age\",\n",
    "    \"Prix\",\"Port\"],dtype={\"Surv\":object,\n",
    "    \"Classe\":object,\"Genre\":object,\"Port\":object},\n",
    "    chunksize=100)\n",
    "# ouverture du fichier HDF5\n",
    "stock=pd.HDFStore(\"titan.h5\")\n",
    "# boucle de lecture\n",
    "for Part in Partition:\n",
    "    # \"nettoyage\" préliminaire des données\n",
    "    #Part=Part.drop([\"Name\",\"Ticket\",\"Cabin\"],axis=1)\n",
    "    # ... autres opérations\n",
    "    # création de la table \"df\" dans \"stock\" puis\n",
    "    # extension de celle-ci par chaque \"Part\"\n",
    "    stock.append(\"df\",Part)\n",
    "# dernier morceau lu et ajouté\n",
    "Part.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il est généralement utile de fermer le fichier\n",
    "stock.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention** aux types implicites des variables. Si, par exemple, une donnée manquante n'apparaît pas dans une colonne du 1er morceau mais dans le 2ème, cela peut engendrer un conflit de type. Expliciter systématiquement les types et noms des variables dans un dictionnaire en paramètre.\n",
    "\n",
    "## Utilisation d'une table HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ouverture du fichier\n",
    "Archiv=pd.HDFStore(\"titan.h5\")\n",
    "# sélection de la table et affichage de l'entête\n",
    "Archiv.select(\"df\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette partie est à développer pour illustrer les fonctionnalités de `pandas` permettant d'interroger / requêter (*querying* notamment SQL) une table archivée dans un fichier HDF5. Consulter la [documentation en ligne](http://pandas.pydata.org/pandas-docs/dev/io.html#hdf5-pytables) à ce sujet. \n",
    "\n",
    "## Echantillon aléatoire simple\n",
    "Le fichier créé au format HDF5 peut être encore très volumineux. Par souci d'efficacité, son raffinement, son exploitation, voire même son analyse pour modélisation, peuvent ou même doivent être opérés sur un  simple échantillon aléatoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction du nombre de lignes  / individus\n",
    "nrows = Archiv.get_storer(\"df\").nrows\n",
    "# génération des index aléatoires\n",
    "r = np.random.randint(0,nrows,size=10)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction des lignes d'index fixés\n",
    "df_ech=Archiv.select(\"df\",where=pd.Index(r))\n",
    "df_ech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il \"suffit\" alors d'appliquer les outils des sections précédentes.\n",
    "\n",
    "## À suivre...\n",
    "Ces traitements font appel à de très nombreuses opérations de lectures / écritures sur un seul ordinateur, un seul disque au regard du volume des calculs ; ils ne sont pas adaptés à une parallélisation sur un ordinateur multiprocesseur. La gestion et l'analyse de plus gros volumes de données nécessite une distribution de celles-ci sur plusieurs serveurs / disques. D'autres technologies doivent être utilisées ; c'est actuellement le couple *Spark/Hadoop* le plus en vogue.\n",
    "\n",
    "**Intérêt** : *Spark* est utilisable avec java, Scala et aussi Python. L'investissement dans ce langage est donc rentable. \n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Références\n",
    "\n",
    "**Mac Kinney W.** (2013). *Python for Data Analysis*, O’Reilly. [pdf](http://it-ebooks.info/book/104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "nav_menu": {
    "height": "512px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
